# --- LLM API Configuration ---
# Your primary API key (OpenAI, Anthropic, or OpenRouter)
LLM_API_KEY=your_api_key_here

# The Base URL for the API provider
# OpenAI Default: https://api.openai.com/v1/chat/completions
# OpenRouter: https://openrouter.ai/api/v1/chat/completions
LLM_API_BASE_URL=https://api.openai.com/v1/chat/completions

# The default model to use if not specified in personas.json
DEFAULT_MODEL=gpt-4-turbo

# --- System Configuration ---
# Timeout for AI requests in seconds
AI_TIMEOUT=60
# Number of retries for failed API calls
MAX_RETRIES=3
# Logging level (DEBUG, INFO, WARNING, ERROR)
LOG_LEVEL=INFO

# --- RAG (Retrieval Augmented Generation) Configuration ---
# Enable or disable the memory system
USE_RAG=true

# The embedding model to use for vectorization
# Options: 'text-embedding-3-small' (OpenAI), 'all-MiniLM-L6-v2' (Local/HuggingFace)
RAG_EMBEDDING_MODEL=text-embedding-3-small

# Path to the persistent vector database
# This will be created inside each project folder automatically
RAG_CHROMA_PATH=memory_db